import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression

## reading all folders in the given data
subfolders = [ f.name for f in os.scandir('/home/nayaks/data') if f.is_dir() ]

##data processing and noise removal

data=[]
count=0
for folder_name in subfolders:
    _,group_no,instance=folder_name.split("_")
    with open (f'/home/nayaks/data/{folder_name}/mem.log') as input_file:
        for line in input_file:
            y=line.split("\":\"")
            y[1]=y[1].replace("\"","")
            timestamp=y[0].replace("\"","")
            Mem_allot,Mem_Used,CPU_allot,CPU_used,bwidth_util,space_util=y[1].split(':')
            space_util=space_util.replace("G\n",'')
            data.append([group_no,instance,timestamp,Mem_allot,Mem_Used,CPU_allot,CPU_used,bwidth_util,space_util])
        
df = pd.DataFrame(data, columns = ['group_no','instance','timestamp','Mem_allot','Mem_used','CPU_allot','CPU_used','bwidth_util','space_util'])

# Select the features to be used in ML model
Xfeatures = ['group','Mem_used','CPU_used','space_util','bwidth_util']
X = dataset[Xfeatures[0]]
y = dataset[Xfeatures[1:]]

# Split dataset to training and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

# Take Logarithm of the num_orders to reduce the amount of impact by outliers
# y_train = np.log10(y_train)
# y_test = np.log10(y_test)

# Fit Regression Model
reg = RandomForestRegressor(n_estimators=50, max_depth=30, n_jobs=-1, warm_start=True)
reg.fit(X_train,y_train)

# Calculate Training and Test Accuracy
training_accuracy = reg.score(X_train, y_train)
test_accuracy = reg.score(X_test, y_test)

# Calculate Root mean squared error
rmse_train = np.sqrt(mean_squared_error(reg.predict(X_train),y_train))
rmse_test = np.sqrt(mean_squared_error(reg.predict(X_test),y_test))
print("Training Accuracy = %0.3f, Test Accuracy = %0.3f, RMSE (train) = %0.3f, RMSE (test) = %0.3f" % (training_accuracy, test_accuracy, rmse_train, rmse_test))

# Print Actual and Predicted values for first 50 test set
#pd.DataFrame(np.round(np.power(10,np.column_stack((reg.predict(X_test),y_test))), decimals=0).astype(int)).head(20)

# Store the trained model
joblib.dump(reg, 'trained_random_forest.pkl')
####predicting for group resource utilization ###

Xfeatures = ['Mem_used','CPU_used','space_util','bwidth_util']
X = df['group_no']
y = df[Xfeatures]
print(len(X))
X = X.values.reshape(-1,1)
y.shape
# y = y.values.reshape(-1,1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)
reg = RandomForestRegressor(n_estimators=50, max_depth=30, n_jobs=-1, warm_start=True)
reg.fit(X_train,y_train)
# reg=LinearRegression()
# reg.fit(X_train,y_train)
# Calculate Training and Test Accuracy
training_accuracy = reg.score(X_train, y_train)
test_accuracy = reg.score(X_test, y_test)
training_accuracy
test_accuracy

### prediction for instance wise resource utilization ###
## converting strings to integers,categorizing
my_dict={}
count=0
for instance in df['instance'].unique():
    my_dict[instance]=0
    count =count+1
for instance in df['instance']:
    df['new_instance']=my_dict[instance]    

Xfeatures = ['Mem_used','CPU_used','space_util','bwidth_util']
X = df['new_instance']
y = df[Xfeatures]
X = X.values.reshape(-1,1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

reg = RandomForestRegressor(n_estimators=50, max_depth=30, n_jobs=-1, warm_start=True)
reg.fit(X_train,y_train)

# Calculate Training and Test Accuracy
training_accuracy = reg.score(X_train, y_train)
test_accuracy = reg.score(X_test, y_test)
